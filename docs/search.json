[
  {
    "objectID": "data/raw/mbsa-qip/readme.html",
    "href": "data/raw/mbsa-qip/readme.html",
    "title": "About the dataset: MBSA-QIP",
    "section": "",
    "text": "Metabolic and bariatric surgery accreditation and quality improvement program (MBSA-QIP) is a dataset available by request / application to the American College of Surgeons (ACS). You may request your own copy of the raw data by completing the ACS Form for the MBSAQIP Participant Use Data File (PUF).\nPlease note: This GitHub repository does not contain any raw data (PUF files provided by the ACS). This repository is a datalad dataset (repository) which is only tracking the presence of the data files and any modifications made by the authorized user, Pranav Mishra (Rush University), for the purpose of this seminar. No other use has access nor is permitted to have access without completing the PUF request form above. All raw data (PUF files) are accessible only to the authorized user on the university’s IT-approved infrastructure.\n\n\n\nAmerican College of Surgeons. Participant Use Data File (PUF). ACS. Published 2024. Accessed February 27, 2024. https://www.facs.org/quality-programs/accreditation-and-verification/metabolic-and-bariatric-surgery-accreditation-and-quality-improvement-program/participant-use-data-file-puf/\nAmerican College of Surgeons. Metabolic and Bariatric Surgery Accreditation and Quality Improvement Program. ACS. Published 2024. Accessed February 27, 2024. https://www.facs.org/quality-programs/accreditation-and-verification/metabolic-and-bariatric-surgery-accreditation-and-quality-improvement-program/\n\n\n\nThe American College of Surgeons Metabolic and Bariatric Surgery Accreditation and Quality Improvement Program and the centers participating in the ACS MBSAQIP are the source of the data used herein; they have not verified and are not responsible for the statistical validity of the data analysis or the conclusions derived by the authors.",
    "crumbs": [
      "Home",
      "Data",
      "Raw",
      "Mbsa Qip",
      "About the dataset: MBSA-QIP"
    ]
  },
  {
    "objectID": "data/raw/mbsa-qip/readme.html#reference-and-disclosure",
    "href": "data/raw/mbsa-qip/readme.html#reference-and-disclosure",
    "title": "About the dataset: MBSA-QIP",
    "section": "",
    "text": "American College of Surgeons. Participant Use Data File (PUF). ACS. Published 2024. Accessed February 27, 2024. https://www.facs.org/quality-programs/accreditation-and-verification/metabolic-and-bariatric-surgery-accreditation-and-quality-improvement-program/participant-use-data-file-puf/\nAmerican College of Surgeons. Metabolic and Bariatric Surgery Accreditation and Quality Improvement Program. ACS. Published 2024. Accessed February 27, 2024. https://www.facs.org/quality-programs/accreditation-and-verification/metabolic-and-bariatric-surgery-accreditation-and-quality-improvement-program/\n\n\n\nThe American College of Surgeons Metabolic and Bariatric Surgery Accreditation and Quality Improvement Program and the centers participating in the ACS MBSAQIP are the source of the data used herein; they have not verified and are not responsible for the statistical validity of the data analysis or the conclusions derived by the authors.",
    "crumbs": [
      "Home",
      "Data",
      "Raw",
      "Mbsa Qip",
      "About the dataset: MBSA-QIP"
    ]
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "v0.0.2 - Migration fixes",
    "section": "",
    "text": "v0.0.2 - Migration fixes\nFix README, CHANGELOG, _quarto.yml\n\n\nv0.0.1 - Migration from temporary repository\nInitializing the repository without any analysis performed",
    "crumbs": [
      "Home",
      "v0.0.2 - Migration fixes"
    ]
  },
  {
    "objectID": "README.html",
    "href": "README.html",
    "title": "Managing your research data: From collection to publication and beyond",
    "section": "",
    "text": "Faculty Affairs and Mentoring Programs Present the Postdoctoral Seminar\nPresenter:\nPranav K. Mishra, MD\nPost-Doctoral Research Fellow\nDepartments of Surgery and Orthopedic Surgery\nRush University\nEvent Details\nMay 29, 2024 (Wednesday)\n3:00 pm – 5:00 pm\nAAC 550A and Zoom\n\n\n\nWhat makes research data storage efficient and compliant with the new NIH guidelines\nBuilding a hierarchy to separate raw, analysis, and publication-level research data\nAutomating steps between the “mundane tasks” and “complex analysis” to save time and improve reproducibility\nHow to access and utilize Rush’s Microsoft 365 cloud storage for 25 TB of storage, per project, for free\n2nd-hour Interactive Session - bring your laptop if you’d like to showcase your setup or get help improving your project!\n\n\n\n\n\nCode for data processing and analysis is located in code/.\nData structure:\n\nRaw data - unmodified / unanalyzed data: /data/raw\nAnalyzed data - processed and analyzed data, generated from the raw data: /data/analysis\nResearch output - figures, tables, text, etc. suitable or submitted for publication (abstract, presentation, journal article)\n\n\n\n\nThe research data is being stored on the pminformatics server on the DATA-3 volume. An RIA storage has been created at this location:\ndatalad create-sibling-ria --new-store-ok -s datalad-ria --existing reconfigure ria+file:///media/pranav/DATA-3/Courses/research-data-management\n\ndatalad siblings add -s origin --url git@github.com:pranavmishra90/courses-by-mishra-research-data-management.git --publish-depends datalad-ria \n\n\n\n\n\n\nconda env create -f code/python/environment.yml\n\n\n\nYou can open each jupyter notebook file individually and see how the code runs. Alternatively, the entire analysis can be performed automatically using papermill. The research notebook is generated using quarto.\nconda activate researchdata\n\ndatalad run --dry-run basic -i data/raw/cms -o data/analysis/bariatric/runs -o notebook/ --explicit --expand both -m \"CMS Analysis: Multiple runs via Datalad\" 'code/shell/papermill/timely_effective.sh'\n\n# Bariatric dataset (requires raw data not available on GitHub)\n# datalad run --dry-run basic -i data/raw/mbsa-qip -o data/analysis/bariatric/runs -o notebook/ --explicit --expand both -m \"MBSAQIP Analysis: Multiple runs via Datalad\" 'code/shell/papermill/bariatric.sh'\n\n\n\n\n\n\n\nThis is a DataLad dataset (id: ebf9a648-e396-4741-a38f-cc40cbf18823).\n\n\n\nThis repository is a DataLad dataset. It provides fine-grained data access down to the level of individual files, and allows for tracking future updates. In order to use this repository for data retrieval, DataLad is required. It is a free and open source command line tool, available for all major operating systems, and builds up on Git and git-annex to allow sharing, synchronizing, and version controlling collections of large files.\nMore information on how to install DataLad and how to install it can be found in the DataLad Handbook.\n\n\nA DataLad dataset can be cloned by running\ndatalad clone https://github.com/pranavmishra90/courses-by-mishra-research-data-management\nOnce a dataset is cloned, it is a light-weight directory on your local machine. At this point, it contains only small metadata and information on the identity of the files in the dataset, but not actual content of the (sometimes large) data files.\n\n\n\nAfter cloning a dataset, you can retrieve file contents by running\ndatalad get &lt;path/to/directory/or/file&gt;\nThis command will trigger a download of the files, directories, or subdatasets you have specified.\nDataLad datasets can contain other datasets, so called subdatasets. If you clone the top-level dataset, subdatasets do not yet contain metadata and information on the identity of files, but appear to be empty directories. In order to retrieve file availability metadata in subdatasets, run\ndatalad get -n &lt;path/to/subdataset&gt;\nAfterwards, you can browse the retrieved metadata to find out about subdataset contents, and retrieve individual files with datalad get. If you use datalad get &lt;path/to/subdataset&gt;, all contents of the subdataset will be downloaded at once.\n\n\n\nDataLad datasets can be updated. The command datalad update will fetch updates and store them on a different branch (by default remotes/origin/master). Running\ndatalad update --merge\nwill pull available updates and integrate them in one go.\n\n\n\nDataLad datasets contain their history in the git log. By running git log (or a tool that displays Git history) in the dataset or on specific files, you can find out what has been done to the dataset or to individual files by whom, and when.",
    "crumbs": [
      "Home",
      "Managing your research data: From collection to publication and beyond"
    ]
  },
  {
    "objectID": "README.html#learning-objectives",
    "href": "README.html#learning-objectives",
    "title": "Managing your research data: From collection to publication and beyond",
    "section": "",
    "text": "What makes research data storage efficient and compliant with the new NIH guidelines\nBuilding a hierarchy to separate raw, analysis, and publication-level research data\nAutomating steps between the “mundane tasks” and “complex analysis” to save time and improve reproducibility\nHow to access and utilize Rush’s Microsoft 365 cloud storage for 25 TB of storage, per project, for free\n2nd-hour Interactive Session - bring your laptop if you’d like to showcase your setup or get help improving your project!",
    "crumbs": [
      "Home",
      "Managing your research data: From collection to publication and beyond"
    ]
  },
  {
    "objectID": "README.html#repository-structure",
    "href": "README.html#repository-structure",
    "title": "Managing your research data: From collection to publication and beyond",
    "section": "",
    "text": "Code for data processing and analysis is located in code/.\nData structure:\n\nRaw data - unmodified / unanalyzed data: /data/raw\nAnalyzed data - processed and analyzed data, generated from the raw data: /data/analysis\nResearch output - figures, tables, text, etc. suitable or submitted for publication (abstract, presentation, journal article)\n\n\n\n\nThe research data is being stored on the pminformatics server on the DATA-3 volume. An RIA storage has been created at this location:\ndatalad create-sibling-ria --new-store-ok -s datalad-ria --existing reconfigure ria+file:///media/pranav/DATA-3/Courses/research-data-management\n\ndatalad siblings add -s origin --url git@github.com:pranavmishra90/courses-by-mishra-research-data-management.git --publish-depends datalad-ria",
    "crumbs": [
      "Home",
      "Managing your research data: From collection to publication and beyond"
    ]
  },
  {
    "objectID": "README.html#instructions",
    "href": "README.html#instructions",
    "title": "Managing your research data: From collection to publication and beyond",
    "section": "",
    "text": "conda env create -f code/python/environment.yml\n\n\n\nYou can open each jupyter notebook file individually and see how the code runs. Alternatively, the entire analysis can be performed automatically using papermill. The research notebook is generated using quarto.\nconda activate researchdata\n\ndatalad run --dry-run basic -i data/raw/cms -o data/analysis/bariatric/runs -o notebook/ --explicit --expand both -m \"CMS Analysis: Multiple runs via Datalad\" 'code/shell/papermill/timely_effective.sh'\n\n# Bariatric dataset (requires raw data not available on GitHub)\n# datalad run --dry-run basic -i data/raw/mbsa-qip -o data/analysis/bariatric/runs -o notebook/ --explicit --expand both -m \"MBSAQIP Analysis: Multiple runs via Datalad\" 'code/shell/papermill/bariatric.sh'",
    "crumbs": [
      "Home",
      "Managing your research data: From collection to publication and beyond"
    ]
  },
  {
    "objectID": "README.html#about-this-dataset",
    "href": "README.html#about-this-dataset",
    "title": "Managing your research data: From collection to publication and beyond",
    "section": "",
    "text": "This is a DataLad dataset (id: ebf9a648-e396-4741-a38f-cc40cbf18823).\n\n\n\nThis repository is a DataLad dataset. It provides fine-grained data access down to the level of individual files, and allows for tracking future updates. In order to use this repository for data retrieval, DataLad is required. It is a free and open source command line tool, available for all major operating systems, and builds up on Git and git-annex to allow sharing, synchronizing, and version controlling collections of large files.\nMore information on how to install DataLad and how to install it can be found in the DataLad Handbook.\n\n\nA DataLad dataset can be cloned by running\ndatalad clone https://github.com/pranavmishra90/courses-by-mishra-research-data-management\nOnce a dataset is cloned, it is a light-weight directory on your local machine. At this point, it contains only small metadata and information on the identity of the files in the dataset, but not actual content of the (sometimes large) data files.\n\n\n\nAfter cloning a dataset, you can retrieve file contents by running\ndatalad get &lt;path/to/directory/or/file&gt;\nThis command will trigger a download of the files, directories, or subdatasets you have specified.\nDataLad datasets can contain other datasets, so called subdatasets. If you clone the top-level dataset, subdatasets do not yet contain metadata and information on the identity of files, but appear to be empty directories. In order to retrieve file availability metadata in subdatasets, run\ndatalad get -n &lt;path/to/subdataset&gt;\nAfterwards, you can browse the retrieved metadata to find out about subdataset contents, and retrieve individual files with datalad get. If you use datalad get &lt;path/to/subdataset&gt;, all contents of the subdataset will be downloaded at once.\n\n\n\nDataLad datasets can be updated. The command datalad update will fetch updates and store them on a different branch (by default remotes/origin/master). Running\ndatalad update --merge\nwill pull available updates and integrate them in one go.\n\n\n\nDataLad datasets contain their history in the git log. By running git log (or a tool that displays Git history) in the dataset or on specific files, you can find out what has been done to the dataset or to individual files by whom, and when.",
    "crumbs": [
      "Home",
      "Managing your research data: From collection to publication and beyond"
    ]
  },
  {
    "objectID": "notebook/references.html",
    "href": "notebook/references.html",
    "title": "References",
    "section": "",
    "text": "12 34 56 7\n\nReferences\n\n\n1. Wolf FA, Angerer P, Theis FJ. SCANPY: Large-scale single-cell gene expression data analysis. Genome Biol. 2018;19(1):15. doi:10.1186/s13059-017-1382-0\n\n\n2. Harris PA, Taylor R, Minor BL, et al. The REDCap consortium: Building an international community of software platform partners. Journal of Biomedical Informatics. 2019;95:103208. doi:10.1016/j.jbi.2019.103208\n\n\n3. American College of Surgeons. Participant use data file (PUF). ACS. Published 2024. Accessed February 27, 2024. https://www.facs.org/quality-programs/accreditation-and-verification/metabolic-and-bariatric-surgery-accreditation-and-quality-improvement-program/participant-use-data-file-puf/\n\n\n4. American College of Surgeons. Metabolic and bariatric surgery accreditation and quality improvement program. ACS. Published 2024. Accessed February 27, 2024. https://www.facs.org/quality-programs/accreditation-and-verification/metabolic-and-bariatric-surgery-accreditation-and-quality-improvement-program/\n\n\n5. Litviňuková M, Talavera-López C, Maatz H, et al. Cells of the adult human heart. Nature. 2020;588(7838):466-472. doi:10.1038/s41586-020-2797-4\n\n\n6. Centers for Medicare and Medicaid Services. Timely and effective care - hospital. Published 2023. Accessed May 29, 2024. https://data.cms.gov/provider-data/dataset/yv7e-xc69#data-table\n\n\n7. Centers for Medicare and Medicaid Services. Healthcare associated infections - hospital. Published 2023. Accessed May 29, 2024. https://data.cms.gov/provider-data/dataset/77hc-ibv8#data-table",
    "crumbs": [
      "Home",
      "Notebook",
      "References"
    ]
  },
  {
    "objectID": "data/raw/cms/readme.html",
    "href": "data/raw/cms/readme.html",
    "title": "About the dataset: CMS Data Sources",
    "section": "",
    "text": "About the dataset: CMS Data Sources\nHealthcare_Associated_Infections-Hospital.csv:1\nTimely_and_Effective_Care-Hospital.csv:2\n\nReferences\n\n\n1. Centers for Medicare and Medicaid Services. Timely and effective care - hospital. Published 2023. Accessed May 29, 2024. https://data.cms.gov/provider-data/dataset/yv7e-xc69#data-table\n\n\n2. Centers for Medicare and Medicaid Services. Healthcare associated infections - hospital. Published 2023. Accessed May 29, 2024. https://data.cms.gov/provider-data/dataset/77hc-ibv8#data-table",
    "crumbs": [
      "Home",
      "Data",
      "Raw",
      "Cms",
      "About the dataset: CMS Data Sources"
    ]
  }
]